{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6df59257-dc25-4447-8ba9-cc6be4d41370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic chatbot using langgraph\n",
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_ollama import ChatOllama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34e1f37d-722e-4985-8365-f8bca1685b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # messages have the type \"list\", \n",
    "    # the add_messages function Annotated list defines how this state key should be updated , in this case, it should append a message to the list rather than overwriting them\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2191f92-0502-4168-ace8-06807a9fc039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a StateGraph instance and pass it our State Class. We will use this to create nodes/edges later on.\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1f7e885-05be-4d44-ba2a-6895b0a49b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.2:3b\")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# now add a node, first argument is the unique node name, second argumnet is the function or object that will be called whenever the node is used\n",
    "\n",
    "graph_builder.add_node(\"chatnode\", chatbot)\n",
    "graph_builder.add_edge(START, \"chatnode\")\n",
    "graph_builder.add_edge(\"chatnode\", END)\n",
    "\n",
    "# finally we compile our graph before we can use it\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a010fdc2-3f6e-47ae-bb9e-9d8232293a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################RANDOM DATE##########################\n",
    "import random\n",
    "import time\n",
    "    \n",
    "def str_time_prop(start, end, time_format, prop):\n",
    "    \"\"\"Get a time at a proportion of a range of two formatted times.\n",
    "\n",
    "    start and end should be strings specifying times formatted in the\n",
    "    given format (strftime-style), giving an interval [start, end].\n",
    "    prop specifies how a proportion of the interval to be taken after\n",
    "    start.  The returned time will be in the specified format.\n",
    "    \"\"\"\n",
    "\n",
    "    stime = time.mktime(time.strptime(start, time_format))\n",
    "    etime = time.mktime(time.strptime(end, time_format))\n",
    "\n",
    "    ptime = stime + prop * (etime - stime)\n",
    "\n",
    "    return time.strftime(time_format, time.localtime(ptime))\n",
    "\n",
    "\n",
    "def random_date(start, end, prop):\n",
    "    return str_time_prop(start, end, '%m/%d/%Y %I:%M %p', prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8564ff5-17c0-419f-b526-d187b5a1505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input:str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\":\"user\", \"content\":user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"cheers\", \"q\"]:\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # a fallback prompt if the user enters nothing\n",
    "        date = random_date(\"1/1/1995 1:30 AM\", \"1/1/2025 4:50 AM\", random.random())\n",
    "        print(f\"what was random date? {date}\")\n",
    "        default_input = f\"What were you doing on the night of the {date}?\" \n",
    "        stream_graph_updates(default_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e837a-b75f-4608-aa12-845d9c8ef6af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
